name: airflow-integration
on: [push]
jobs:
  integrate-aiflow:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v2

      - name: Setup Python
        uses: actions/setup-python@v2
        with:
          python-version: 3.9

      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip wheel
          pip install flake8 pytest
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi

      - name: Run Flake8 Linter
        run: |
          # Stop build if any of the follow error/warning groups trigger
          flake8 . --count --select=E4,E7,E9,F4,F6,F7,F8,F9,W1 --show-source --statistics --exclude=__init__.py
          # exit-zero treats all errors as warnings. The GitHub editor is 127 characters wide
          flake8 . --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics

      - name: Run Test-Suite
        run: |
          if [ -f .env.sample ]; then cp .env.sample .env; fi
          pytest

      - name: Zip Plugins
        run: |
          cd plugins
          chmod -R 755 .
          zip -r plugins.zip .
          mv plugins.zip ../.
          cd ..

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_AIRFLOW_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_AIRFLOW_ACCESS_SECRET_KEY }}
          aws-region: us-east-1

      - name: Upload to S3
        run: |
          aws s3 cp plugins.zip s3://airflow-gar-testing/plugins.zip
          aws s3 cp requirements.txt s3://airflow-gar-testing/requirements.txt
          aws s3 sync ./dags/ s3://airflow-gar-testing/dags/ --exclude="*" --include="*.py"

      - name: Update AWS Airflow S3 Object Versions
        run: |
          echo ${{ secrets.AWS_AIRFLOW_S3_BUCKET }}
